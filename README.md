# Awesome Mamba Models
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)]([https://github.com/ZhiningLiu1998/awesome-imbalanced-learning](https://github.com/yanliang3612/awesome-mamba)) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

This repository contains a collection of resources and papers on ***Mamba Models for different domains***. We are pleased to see that more and more efforts have been devoted to dealing with ***structured state space models*** since 2023.

If you have any relevant paper or codes to update the list, please pull a request or report an issue. 

## Mamba
[Mamba](https://github.com/state-spaces/mamba) is a new state-space model architecture showing promising performance on language modeling with O(N) complexity.

[mamba.py üêç : a simple and efficient Mamba implementation](https://github.com/alxndrTL/mamba.py)

[Mamba-jax](https://github.com/vvvm23/mamba-jax)

[Mamba-minimal-pytorch](https://github.com/johnma2006/mamba-minimal)

[Mamba-minimal-in-JAX](https://github.com/radarFudan/mamba-minimal-jax)

## Computer Vision

[Efficient Visual Representation Learning with Bidirectional State Space Model](https://github.com/hustvl/Vim)

[MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration](https://github.com/Guo-Stone/MambaMorph)

[Vivim: a Video Vision Mamba for Medical Video Object Segmentation](https://github.com/scott-yjyang/Vivim)

[SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation](https://github.com/ge-xing/SegMamba)

[VMamba: Visual State Space Model](https://github.com/MzeroMiko/VMamba)

[U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation](https://github.com/bowang-lab/U-Mamba)

[Swin-UMamba](https://github.com/JiarunLiu/Swin-UMamba)

[VM-UNet](https://github.com/JCruan519/VM-UNet)

## NLP

[MambaByte: Token-free Selective State Space Model](https://github.com/kyegomez/MambaByte)

[MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://arxiv.org/abs/2401.04081)

[BlackMamba: Mixture of Experts for State-Space Models](https://static1.squarespace.com/static/658ded386c43c219ee47caba/t/65bd73200920d050ccbac40c/1706914594353/blackMamba.pdf)

[Repeat After Me: Transformers are Better than State Space Models at Copying](https://arxiv.org/pdf/2402.01032.pdf)

[Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks](https://arxiv.org/pdf/2402.04248.pdf)

[LOCOST: State-Space Models for Long Document Abstractive Summarization](https://arxiv.org/abs/2401.17919)

## Graph

[Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces](https://github.com/bowang-lab/Graph-Mamba)

[Graph Mamba: Towards Learning on Graphs with State Space Models](https://arxiv.org/abs/2402.08678)

## Theory

[Universality-1](https://arxiv.org/abs/2309.13414)

[Universality-2](https://arxiv.org/abs/2307.11888)

[StableSSM](http://arxiv.org/abs/2311.14495)

[Generalization](https://openreview.net/forum?id=EGjvMcKrrl&noteId=eWRltAW3XY)

## Acknowledgement

- [@yanliang2612](https://github.com/yanliang3612) 
